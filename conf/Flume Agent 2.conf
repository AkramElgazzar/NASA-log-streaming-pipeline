# Name the components
agent2.sources = kafka_source
agent2.channels = memory_channel
agent2.sinks = hdfs_sink

# Configure Kafka source
agent2.sources.kafka_source.type = org.apache.flume.source.kafka.KafkaSource
agent2.sources.kafka_source.batchSize = 500
agent2.sources.kafka_source.batchDurationMillis = 2000
agent2.sources.kafka_source.kafka.bootstrap.servers = localhost:9092
agent2.sources.kafka_source.kafka.topics = apache_logs
agent2.sources.kafka_source.kafka.consumer.group.id = flume_consumer

# Configure the memory channel
agent2.channels.memory_channel.type = memory
agent2.channels.memory_channel.capacity = 100000
agent2.channels.memory_channel.transactionCapacity = 1000

# Configure the HDFS sink
agent2.sinks.hdfs_sink.type = hdfs
agent2.sinks.hdfs_sink.hdfs.path = hdfs:///user/bigdata/apache_logs/%y-%m-%d
agent2.sinks.hdfs_sink.hdfs.filePrefix = apache_logs
agent2.sinks.hdfs_sink.hdfs.fileSuffix = .log
agent2.sinks.hdfs_sink.hdfs.rollInterval = 300
agent2.sinks.hdfs_sink.hdfs.rollSize = 0
agent2.sinks.hdfs_sink.hdfs.rollCount = 0
agent2.sinks.hdfs_sink.hdfs.fileType = DataStream
agent2.sinks.hdfs_sink.hdfs.writeFormat = Text

# Bind the source and sink to the channel
agent2.sources.kafka_source.channels = memory_channel
agent2.sinks.hdfs_sink.channel = memory_channel